{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.78\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 747.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "vgg = models.vgg16()\n",
    "summary(vgg, (3, 224, 224), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 640, 640]             864\n",
      "       BatchNorm2d-2         [-1, 32, 640, 640]              64\n",
      "            Conv2d-3         [-1, 64, 320, 320]          18,432\n",
      "       BatchNorm2d-4         [-1, 64, 320, 320]             128\n",
      "            Conv2d-5         [-1, 32, 320, 320]           2,048\n",
      "       BatchNorm2d-6         [-1, 32, 320, 320]              64\n",
      "            Conv2d-7         [-1, 64, 320, 320]          18,432\n",
      "       BatchNorm2d-8         [-1, 64, 320, 320]             128\n",
      "        DownSample-9         [-1, 64, 320, 320]               0\n",
      "           Conv2d-10        [-1, 128, 160, 160]          73,728\n",
      "      BatchNorm2d-11        [-1, 128, 160, 160]             256\n",
      "           Conv2d-12         [-1, 64, 160, 160]           8,192\n",
      "      BatchNorm2d-13         [-1, 64, 160, 160]             128\n",
      "           Conv2d-14        [-1, 128, 160, 160]          73,728\n",
      "      BatchNorm2d-15        [-1, 128, 160, 160]             256\n",
      "       DownSample-16        [-1, 128, 160, 160]               0\n",
      "           Conv2d-17         [-1, 64, 160, 160]           8,192\n",
      "      BatchNorm2d-18         [-1, 64, 160, 160]             128\n",
      "           Conv2d-19        [-1, 128, 160, 160]          73,728\n",
      "      BatchNorm2d-20        [-1, 128, 160, 160]             256\n",
      "       BasicBlock-21        [-1, 128, 160, 160]               0\n",
      "           Conv2d-22          [-1, 256, 80, 80]         294,912\n",
      "      BatchNorm2d-23          [-1, 256, 80, 80]             512\n",
      "           Conv2d-24          [-1, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-25          [-1, 128, 80, 80]             256\n",
      "           Conv2d-26          [-1, 256, 80, 80]         294,912\n",
      "      BatchNorm2d-27          [-1, 256, 80, 80]             512\n",
      "       DownSample-28          [-1, 256, 80, 80]               0\n",
      "           Conv2d-29          [-1, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-30          [-1, 128, 80, 80]             256\n",
      "           Conv2d-31          [-1, 256, 80, 80]         294,912\n",
      "      BatchNorm2d-32          [-1, 256, 80, 80]             512\n",
      "       BasicBlock-33          [-1, 256, 80, 80]               0\n",
      "           Conv2d-34          [-1, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-35          [-1, 128, 80, 80]             256\n",
      "           Conv2d-36          [-1, 256, 80, 80]         294,912\n",
      "      BatchNorm2d-37          [-1, 256, 80, 80]             512\n",
      "       BasicBlock-38          [-1, 256, 80, 80]               0\n",
      "           Conv2d-39          [-1, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-40          [-1, 128, 80, 80]             256\n",
      "           Conv2d-41          [-1, 256, 80, 80]         294,912\n",
      "      BatchNorm2d-42          [-1, 256, 80, 80]             512\n",
      "       BasicBlock-43          [-1, 256, 80, 80]               0\n",
      "           Conv2d-44          [-1, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-45          [-1, 128, 80, 80]             256\n",
      "           Conv2d-46          [-1, 256, 80, 80]         294,912\n",
      "      BatchNorm2d-47          [-1, 256, 80, 80]             512\n",
      "       BasicBlock-48          [-1, 256, 80, 80]               0\n",
      "           Conv2d-49          [-1, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-50          [-1, 128, 80, 80]             256\n",
      "           Conv2d-51          [-1, 256, 80, 80]         294,912\n",
      "      BatchNorm2d-52          [-1, 256, 80, 80]             512\n",
      "       BasicBlock-53          [-1, 256, 80, 80]               0\n",
      "           Conv2d-54          [-1, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-55          [-1, 128, 80, 80]             256\n",
      "           Conv2d-56          [-1, 256, 80, 80]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 80, 80]             512\n",
      "       BasicBlock-58          [-1, 256, 80, 80]               0\n",
      "           Conv2d-59          [-1, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-60          [-1, 128, 80, 80]             256\n",
      "           Conv2d-61          [-1, 256, 80, 80]         294,912\n",
      "      BatchNorm2d-62          [-1, 256, 80, 80]             512\n",
      "       BasicBlock-63          [-1, 256, 80, 80]               0\n",
      "           Conv2d-64          [-1, 512, 40, 40]       1,179,648\n",
      "      BatchNorm2d-65          [-1, 512, 40, 40]           1,024\n",
      "           Conv2d-66          [-1, 256, 40, 40]         131,072\n",
      "      BatchNorm2d-67          [-1, 256, 40, 40]             512\n",
      "           Conv2d-68          [-1, 512, 40, 40]       1,179,648\n",
      "      BatchNorm2d-69          [-1, 512, 40, 40]           1,024\n",
      "       DownSample-70          [-1, 512, 40, 40]               0\n",
      "           Conv2d-71          [-1, 256, 40, 40]         131,072\n",
      "      BatchNorm2d-72          [-1, 256, 40, 40]             512\n",
      "           Conv2d-73          [-1, 512, 40, 40]       1,179,648\n",
      "      BatchNorm2d-74          [-1, 512, 40, 40]           1,024\n",
      "       BasicBlock-75          [-1, 512, 40, 40]               0\n",
      "           Conv2d-76          [-1, 256, 40, 40]         131,072\n",
      "      BatchNorm2d-77          [-1, 256, 40, 40]             512\n",
      "           Conv2d-78          [-1, 512, 40, 40]       1,179,648\n",
      "      BatchNorm2d-79          [-1, 512, 40, 40]           1,024\n",
      "       BasicBlock-80          [-1, 512, 40, 40]               0\n",
      "           Conv2d-81          [-1, 256, 40, 40]         131,072\n",
      "      BatchNorm2d-82          [-1, 256, 40, 40]             512\n",
      "           Conv2d-83          [-1, 512, 40, 40]       1,179,648\n",
      "      BatchNorm2d-84          [-1, 512, 40, 40]           1,024\n",
      "       BasicBlock-85          [-1, 512, 40, 40]               0\n",
      "           Conv2d-86          [-1, 256, 40, 40]         131,072\n",
      "      BatchNorm2d-87          [-1, 256, 40, 40]             512\n",
      "           Conv2d-88          [-1, 512, 40, 40]       1,179,648\n",
      "      BatchNorm2d-89          [-1, 512, 40, 40]           1,024\n",
      "       BasicBlock-90          [-1, 512, 40, 40]               0\n",
      "           Conv2d-91         [-1, 1024, 20, 20]       4,718,592\n",
      "      BatchNorm2d-92         [-1, 1024, 20, 20]           2,048\n",
      "           Conv2d-93          [-1, 512, 20, 20]         524,288\n",
      "      BatchNorm2d-94          [-1, 512, 20, 20]           1,024\n",
      "           Conv2d-95         [-1, 1024, 20, 20]       4,718,592\n",
      "      BatchNorm2d-96         [-1, 1024, 20, 20]           2,048\n",
      "       DownSample-97         [-1, 1024, 20, 20]               0\n",
      "           Conv2d-98          [-1, 512, 20, 20]         524,288\n",
      "      BatchNorm2d-99          [-1, 512, 20, 20]           1,024\n",
      "          Conv2d-100         [-1, 1024, 20, 20]       4,718,592\n",
      "     BatchNorm2d-101         [-1, 1024, 20, 20]           2,048\n",
      "      BasicBlock-102         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-103          [-1, 512, 20, 20]         524,288\n",
      "     BatchNorm2d-104          [-1, 512, 20, 20]           1,024\n",
      "          Conv2d-105         [-1, 1024, 20, 20]       4,718,592\n",
      "     BatchNorm2d-106         [-1, 1024, 20, 20]           2,048\n",
      "      BasicBlock-107         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-108          [-1, 512, 20, 20]         524,288\n",
      "     BatchNorm2d-109          [-1, 512, 20, 20]           1,024\n",
      "          Conv2d-110         [-1, 1024, 20, 20]       4,718,592\n",
      "     BatchNorm2d-111         [-1, 1024, 20, 20]           2,048\n",
      "      BasicBlock-112         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-113         [-1, 2048, 10, 10]      18,874,368\n",
      "     BatchNorm2d-114         [-1, 2048, 10, 10]           4,096\n",
      "          Conv2d-115         [-1, 1024, 10, 10]       2,097,152\n",
      "     BatchNorm2d-116         [-1, 1024, 10, 10]           2,048\n",
      "          Conv2d-117         [-1, 2048, 10, 10]      18,874,368\n",
      "     BatchNorm2d-118         [-1, 2048, 10, 10]           4,096\n",
      "      DownSample-119         [-1, 2048, 10, 10]               0\n",
      "          Conv2d-120         [-1, 1024, 10, 10]       2,097,152\n",
      "     BatchNorm2d-121         [-1, 1024, 10, 10]           2,048\n",
      "          Conv2d-122         [-1, 2048, 10, 10]      18,874,368\n",
      "     BatchNorm2d-123         [-1, 2048, 10, 10]           4,096\n",
      "      BasicBlock-124         [-1, 2048, 10, 10]               0\n",
      "          Conv2d-125         [-1, 1024, 10, 10]       2,097,152\n",
      "     BatchNorm2d-126         [-1, 1024, 10, 10]           2,048\n",
      "          Conv2d-127         [-1, 2048, 10, 10]      18,874,368\n",
      "     BatchNorm2d-128         [-1, 2048, 10, 10]           4,096\n",
      "      BasicBlock-129         [-1, 2048, 10, 10]               0\n",
      "          Conv2d-130           [-1, 4096, 5, 5]      75,497,472\n",
      "     BatchNorm2d-131           [-1, 4096, 5, 5]           8,192\n",
      "          Conv2d-132           [-1, 2048, 5, 5]       8,388,608\n",
      "     BatchNorm2d-133           [-1, 2048, 5, 5]           4,096\n",
      "          Conv2d-134           [-1, 4096, 5, 5]      75,497,472\n",
      "     BatchNorm2d-135           [-1, 4096, 5, 5]           8,192\n",
      "      DownSample-136           [-1, 4096, 5, 5]               0\n",
      "          Conv2d-137           [-1, 2048, 5, 5]       8,388,608\n",
      "     BatchNorm2d-138           [-1, 2048, 5, 5]           4,096\n",
      "          Conv2d-139           [-1, 4096, 5, 5]      75,497,472\n",
      "     BatchNorm2d-140           [-1, 4096, 5, 5]           8,192\n",
      "      BasicBlock-141           [-1, 4096, 5, 5]               0\n",
      "          Conv2d-142           [-1, 2048, 5, 5]       8,388,608\n",
      "     BatchNorm2d-143           [-1, 2048, 5, 5]           4,096\n",
      "          Conv2d-144           [-1, 4096, 5, 5]      75,497,472\n",
      "     BatchNorm2d-145           [-1, 4096, 5, 5]           8,192\n",
      "      BasicBlock-146           [-1, 4096, 5, 5]               0\n",
      "          Conv2d-147           [-1, 2048, 5, 5]       8,388,608\n",
      "     BatchNorm2d-148           [-1, 2048, 5, 5]           4,096\n",
      "          Conv2d-149           [-1, 4096, 5, 5]      75,497,472\n",
      "     BatchNorm2d-150           [-1, 4096, 5, 5]           8,192\n",
      "          Conv2d-151             [-1, 21, 5, 5]          86,016\n",
      "     BatchNorm2d-152             [-1, 21, 5, 5]              42\n",
      "================================================================\n",
      "Total params: 529,644,810\n",
      "Trainable params: 529,644,810\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.69\n",
      "Forward/backward pass size (MB): 1403.91\n",
      "Params size (MB): 2020.43\n",
      "Estimated Total Size (MB): 3429.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "model = PAE()\n",
    "summary(model, (3, 640, 640), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DopeNetwork(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained=False,\n",
    "            numBeliefMap=9,\n",
    "            numAffinity=16,\n",
    "            stop_at_stage=6  # number of stages to process (if less than total number of stages)\n",
    "        ):\n",
    "        super(DopeNetwork, self).__init__()\n",
    "\n",
    "        self.stop_at_stage = stop_at_stage\n",
    "        \n",
    "        if pretrained is False:\n",
    "            print(\"Training network without imagenet weights.\")\n",
    "        else:\n",
    "            print(\"Training network pretrained on imagenet.\")\n",
    "\n",
    "        vgg_full = models.vgg19(pretrained=pretrained).features\n",
    "        self.vgg = nn.Sequential()\n",
    "        for i_layer in range(24):\n",
    "            self.vgg.add_module(str(i_layer), vgg_full[i_layer])\n",
    "\n",
    "        # Add some layers\n",
    "        i_layer = 23\n",
    "        self.vgg.add_module(str(i_layer), nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1))\n",
    "        self.vgg.add_module(str(i_layer+1), nn.ReLU(inplace=True))\n",
    "        self.vgg.add_module(str(i_layer+2), nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1))\n",
    "        self.vgg.add_module(str(i_layer+3), nn.ReLU(inplace=True))\n",
    "\n",
    "        # print('---Belief------------------------------------------------')\n",
    "        # _2 are the belief map stages\n",
    "        self.m1_2 = DopeNetwork.create_stage(128, numBeliefMap, True)\n",
    "        self.m2_2 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numBeliefMap, False)\n",
    "        self.m3_2 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numBeliefMap, False)\n",
    "        self.m4_2 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numBeliefMap, False)\n",
    "        self.m5_2 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numBeliefMap, False)\n",
    "        self.m6_2 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numBeliefMap, False)\n",
    "\n",
    "        # print('---Affinity----------------------------------------------')\n",
    "        # _1 are the affinity map stages\n",
    "        self.m1_1 = DopeNetwork.create_stage(128, numAffinity, True)\n",
    "        self.m2_1 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numAffinity, False)\n",
    "        self.m3_1 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numAffinity, False)\n",
    "        self.m4_1 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numAffinity, False)\n",
    "        self.m5_1 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numAffinity, False)\n",
    "        self.m6_1 = DopeNetwork.create_stage(128 + numBeliefMap + numAffinity,\n",
    "                                             numAffinity, False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Runs inference on the neural network'''\n",
    "\n",
    "        out1 = self.vgg(x)\n",
    "\n",
    "        out1_2 = self.m1_2(out1)\n",
    "        out1_1 = self.m1_1(out1)\n",
    "\n",
    "        if self.stop_at_stage == 1:\n",
    "            return [out1_2],\\\n",
    "                   [out1_1]\n",
    "\n",
    "        out2 = torch.cat([out1_2, out1_1, out1], 1)\n",
    "        out2_2 = self.m2_2(out2)\n",
    "        out2_1 = self.m2_1(out2)\n",
    "\n",
    "        if self.stop_at_stage == 2:\n",
    "            return [out1_2, out2_2],\\\n",
    "                   [out1_1, out2_1]\n",
    "\n",
    "        out3 = torch.cat([out2_2, out2_1, out1], 1)\n",
    "        out3_2 = self.m3_2(out3)\n",
    "        out3_1 = self.m3_1(out3)\n",
    "\n",
    "        if self.stop_at_stage == 3:\n",
    "            return [out1_2, out2_2, out3_2],\\\n",
    "                   [out1_1, out2_1, out3_1]\n",
    "\n",
    "        out4 = torch.cat([out3_2, out3_1, out1], 1)\n",
    "        out4_2 = self.m4_2(out4)\n",
    "        out4_1 = self.m4_1(out4)\n",
    "\n",
    "        if self.stop_at_stage == 4:\n",
    "            return [out1_2, out2_2, out3_2, out4_2],\\\n",
    "                   [out1_1, out2_1, out3_1, out4_1]\n",
    "\n",
    "        out5 = torch.cat([out4_2, out4_1, out1], 1)\n",
    "        out5_2 = self.m5_2(out5)\n",
    "        out5_1 = self.m5_1(out5)\n",
    "\n",
    "        if self.stop_at_stage == 5:\n",
    "            return [out1_2, out2_2, out3_2, out4_2, out5_2],\\\n",
    "                   [out1_1, out2_1, out3_1, out4_1, out5_1]\n",
    "\n",
    "        out6 = torch.cat([out5_2, out5_1, out1], 1)\n",
    "        out6_2 = self.m6_2(out6)\n",
    "        out6_1 = self.m6_1(out6)\n",
    "\n",
    "        return [out1_2, out2_2, out3_2, out4_2, out5_2, out6_2],\\\n",
    "               [out1_1, out2_1, out3_1, out4_1, out5_1, out6_1]\n",
    "                        \n",
    "    @staticmethod\n",
    "    def create_stage(in_channels, out_channels, first=False):\n",
    "        '''Create the neural network layers for a single stage.'''\n",
    "\n",
    "        model = nn.Sequential()\n",
    "        mid_channels = 128\n",
    "        if first:\n",
    "            padding = 1\n",
    "            kernel = 3\n",
    "            count = 6\n",
    "            final_channels = 512\n",
    "        else:\n",
    "            padding = 3\n",
    "            kernel = 7\n",
    "            count = 10\n",
    "            final_channels = mid_channels\n",
    "\n",
    "        # First convolution\n",
    "        model.add_module(\"0\",\n",
    "                         nn.Conv2d(\n",
    "                             in_channels,\n",
    "                             mid_channels,\n",
    "                             kernel_size=kernel,\n",
    "                             stride=1,\n",
    "                             padding=padding)\n",
    "                        )\n",
    "\n",
    "        # Middle convolutions\n",
    "        i = 1\n",
    "        while i < count - 1:\n",
    "            model.add_module(str(i), nn.ReLU(inplace=True))\n",
    "            i += 1\n",
    "            model.add_module(str(i),\n",
    "                             nn.Conv2d(\n",
    "                                 mid_channels,\n",
    "                                 mid_channels,\n",
    "                                 kernel_size=kernel,\n",
    "                                 stride=1,\n",
    "                                 padding=padding))\n",
    "            i += 1\n",
    "\n",
    "        # Penultimate convolution\n",
    "        model.add_module(str(i), nn.ReLU(inplace=True))\n",
    "        i += 1\n",
    "        model.add_module(str(i), nn.Conv2d(mid_channels, final_channels, kernel_size=1, stride=1))\n",
    "        i += 1\n",
    "\n",
    "        # Last convolution\n",
    "        model.add_module(str(i), nn.ReLU(inplace=True))\n",
    "        i += 1\n",
    "        model.add_module(str(i), nn.Conv2d(final_channels, out_channels, kernel_size=1, stride=1))\n",
    "        i += 1\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network without imagenet weights.\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 640, 640]           1,792\n",
      "              ReLU-2         [-1, 64, 640, 640]               0\n",
      "            Conv2d-3         [-1, 64, 640, 640]          36,928\n",
      "              ReLU-4         [-1, 64, 640, 640]               0\n",
      "         MaxPool2d-5         [-1, 64, 320, 320]               0\n",
      "            Conv2d-6        [-1, 128, 320, 320]          73,856\n",
      "              ReLU-7        [-1, 128, 320, 320]               0\n",
      "            Conv2d-8        [-1, 128, 320, 320]         147,584\n",
      "              ReLU-9        [-1, 128, 320, 320]               0\n",
      "        MaxPool2d-10        [-1, 128, 160, 160]               0\n",
      "           Conv2d-11        [-1, 256, 160, 160]         295,168\n",
      "             ReLU-12        [-1, 256, 160, 160]               0\n",
      "           Conv2d-13        [-1, 256, 160, 160]         590,080\n",
      "             ReLU-14        [-1, 256, 160, 160]               0\n",
      "           Conv2d-15        [-1, 256, 160, 160]         590,080\n",
      "             ReLU-16        [-1, 256, 160, 160]               0\n",
      "           Conv2d-17        [-1, 256, 160, 160]         590,080\n",
      "             ReLU-18        [-1, 256, 160, 160]               0\n",
      "        MaxPool2d-19          [-1, 256, 80, 80]               0\n",
      "           Conv2d-20          [-1, 512, 80, 80]       1,180,160\n",
      "             ReLU-21          [-1, 512, 80, 80]               0\n",
      "           Conv2d-22          [-1, 512, 80, 80]       2,359,808\n",
      "             ReLU-23          [-1, 512, 80, 80]               0\n",
      "           Conv2d-24          [-1, 256, 80, 80]       1,179,904\n",
      "             ReLU-25          [-1, 256, 80, 80]               0\n",
      "           Conv2d-26          [-1, 128, 80, 80]         295,040\n",
      "             ReLU-27          [-1, 128, 80, 80]               0\n",
      "           Conv2d-28          [-1, 128, 80, 80]         147,584\n",
      "             ReLU-29          [-1, 128, 80, 80]               0\n",
      "           Conv2d-30          [-1, 128, 80, 80]         147,584\n",
      "             ReLU-31          [-1, 128, 80, 80]               0\n",
      "           Conv2d-32          [-1, 128, 80, 80]         147,584\n",
      "             ReLU-33          [-1, 128, 80, 80]               0\n",
      "           Conv2d-34          [-1, 512, 80, 80]          66,048\n",
      "             ReLU-35          [-1, 512, 80, 80]               0\n",
      "           Conv2d-36            [-1, 9, 80, 80]           4,617\n",
      "           Conv2d-37          [-1, 128, 80, 80]         147,584\n",
      "             ReLU-38          [-1, 128, 80, 80]               0\n",
      "           Conv2d-39          [-1, 128, 80, 80]         147,584\n",
      "             ReLU-40          [-1, 128, 80, 80]               0\n",
      "           Conv2d-41          [-1, 128, 80, 80]         147,584\n",
      "             ReLU-42          [-1, 128, 80, 80]               0\n",
      "           Conv2d-43          [-1, 512, 80, 80]          66,048\n",
      "             ReLU-44          [-1, 512, 80, 80]               0\n",
      "           Conv2d-45           [-1, 16, 80, 80]           8,208\n",
      "           Conv2d-46          [-1, 128, 80, 80]         959,744\n",
      "             ReLU-47          [-1, 128, 80, 80]               0\n",
      "           Conv2d-48          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-49          [-1, 128, 80, 80]               0\n",
      "           Conv2d-50          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-51          [-1, 128, 80, 80]               0\n",
      "           Conv2d-52          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-53          [-1, 128, 80, 80]               0\n",
      "           Conv2d-54          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-55          [-1, 128, 80, 80]               0\n",
      "           Conv2d-56          [-1, 128, 80, 80]          16,512\n",
      "             ReLU-57          [-1, 128, 80, 80]               0\n",
      "           Conv2d-58            [-1, 9, 80, 80]           1,161\n",
      "           Conv2d-59          [-1, 128, 80, 80]         959,744\n",
      "             ReLU-60          [-1, 128, 80, 80]               0\n",
      "           Conv2d-61          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-62          [-1, 128, 80, 80]               0\n",
      "           Conv2d-63          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-64          [-1, 128, 80, 80]               0\n",
      "           Conv2d-65          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-66          [-1, 128, 80, 80]               0\n",
      "           Conv2d-67          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-68          [-1, 128, 80, 80]               0\n",
      "           Conv2d-69          [-1, 128, 80, 80]          16,512\n",
      "             ReLU-70          [-1, 128, 80, 80]               0\n",
      "           Conv2d-71           [-1, 16, 80, 80]           2,064\n",
      "           Conv2d-72          [-1, 128, 80, 80]         959,744\n",
      "             ReLU-73          [-1, 128, 80, 80]               0\n",
      "           Conv2d-74          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-75          [-1, 128, 80, 80]               0\n",
      "           Conv2d-76          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-77          [-1, 128, 80, 80]               0\n",
      "           Conv2d-78          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-79          [-1, 128, 80, 80]               0\n",
      "           Conv2d-80          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-81          [-1, 128, 80, 80]               0\n",
      "           Conv2d-82          [-1, 128, 80, 80]          16,512\n",
      "             ReLU-83          [-1, 128, 80, 80]               0\n",
      "           Conv2d-84            [-1, 9, 80, 80]           1,161\n",
      "           Conv2d-85          [-1, 128, 80, 80]         959,744\n",
      "             ReLU-86          [-1, 128, 80, 80]               0\n",
      "           Conv2d-87          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-88          [-1, 128, 80, 80]               0\n",
      "           Conv2d-89          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-90          [-1, 128, 80, 80]               0\n",
      "           Conv2d-91          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-92          [-1, 128, 80, 80]               0\n",
      "           Conv2d-93          [-1, 128, 80, 80]         802,944\n",
      "             ReLU-94          [-1, 128, 80, 80]               0\n",
      "           Conv2d-95          [-1, 128, 80, 80]          16,512\n",
      "             ReLU-96          [-1, 128, 80, 80]               0\n",
      "           Conv2d-97           [-1, 16, 80, 80]           2,064\n",
      "           Conv2d-98          [-1, 128, 80, 80]         959,744\n",
      "             ReLU-99          [-1, 128, 80, 80]               0\n",
      "          Conv2d-100          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-101          [-1, 128, 80, 80]               0\n",
      "          Conv2d-102          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-103          [-1, 128, 80, 80]               0\n",
      "          Conv2d-104          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-105          [-1, 128, 80, 80]               0\n",
      "          Conv2d-106          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-107          [-1, 128, 80, 80]               0\n",
      "          Conv2d-108          [-1, 128, 80, 80]          16,512\n",
      "            ReLU-109          [-1, 128, 80, 80]               0\n",
      "          Conv2d-110            [-1, 9, 80, 80]           1,161\n",
      "          Conv2d-111          [-1, 128, 80, 80]         959,744\n",
      "            ReLU-112          [-1, 128, 80, 80]               0\n",
      "          Conv2d-113          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-114          [-1, 128, 80, 80]               0\n",
      "          Conv2d-115          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-116          [-1, 128, 80, 80]               0\n",
      "          Conv2d-117          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-118          [-1, 128, 80, 80]               0\n",
      "          Conv2d-119          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-120          [-1, 128, 80, 80]               0\n",
      "          Conv2d-121          [-1, 128, 80, 80]          16,512\n",
      "            ReLU-122          [-1, 128, 80, 80]               0\n",
      "          Conv2d-123           [-1, 16, 80, 80]           2,064\n",
      "          Conv2d-124          [-1, 128, 80, 80]         959,744\n",
      "            ReLU-125          [-1, 128, 80, 80]               0\n",
      "          Conv2d-126          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-127          [-1, 128, 80, 80]               0\n",
      "          Conv2d-128          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-129          [-1, 128, 80, 80]               0\n",
      "          Conv2d-130          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-131          [-1, 128, 80, 80]               0\n",
      "          Conv2d-132          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-133          [-1, 128, 80, 80]               0\n",
      "          Conv2d-134          [-1, 128, 80, 80]          16,512\n",
      "            ReLU-135          [-1, 128, 80, 80]               0\n",
      "          Conv2d-136            [-1, 9, 80, 80]           1,161\n",
      "          Conv2d-137          [-1, 128, 80, 80]         959,744\n",
      "            ReLU-138          [-1, 128, 80, 80]               0\n",
      "          Conv2d-139          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-140          [-1, 128, 80, 80]               0\n",
      "          Conv2d-141          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-142          [-1, 128, 80, 80]               0\n",
      "          Conv2d-143          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-144          [-1, 128, 80, 80]               0\n",
      "          Conv2d-145          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-146          [-1, 128, 80, 80]               0\n",
      "          Conv2d-147          [-1, 128, 80, 80]          16,512\n",
      "            ReLU-148          [-1, 128, 80, 80]               0\n",
      "          Conv2d-149           [-1, 16, 80, 80]           2,064\n",
      "          Conv2d-150          [-1, 128, 80, 80]         959,744\n",
      "            ReLU-151          [-1, 128, 80, 80]               0\n",
      "          Conv2d-152          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-153          [-1, 128, 80, 80]               0\n",
      "          Conv2d-154          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-155          [-1, 128, 80, 80]               0\n",
      "          Conv2d-156          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-157          [-1, 128, 80, 80]               0\n",
      "          Conv2d-158          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-159          [-1, 128, 80, 80]               0\n",
      "          Conv2d-160          [-1, 128, 80, 80]          16,512\n",
      "            ReLU-161          [-1, 128, 80, 80]               0\n",
      "          Conv2d-162            [-1, 9, 80, 80]           1,161\n",
      "          Conv2d-163          [-1, 128, 80, 80]         959,744\n",
      "            ReLU-164          [-1, 128, 80, 80]               0\n",
      "          Conv2d-165          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-166          [-1, 128, 80, 80]               0\n",
      "          Conv2d-167          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-168          [-1, 128, 80, 80]               0\n",
      "          Conv2d-169          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-170          [-1, 128, 80, 80]               0\n",
      "          Conv2d-171          [-1, 128, 80, 80]         802,944\n",
      "            ReLU-172          [-1, 128, 80, 80]               0\n",
      "          Conv2d-173          [-1, 128, 80, 80]          16,512\n",
      "            ReLU-174          [-1, 128, 80, 80]               0\n",
      "          Conv2d-175           [-1, 16, 80, 80]           2,064\n",
      "================================================================\n",
      "Total params: 50,267,350\n",
      "Trainable params: 50,267,350\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.69\n",
      "Forward/backward pass size (MB): 2757.32\n",
      "Params size (MB): 191.75\n",
      "Estimated Total Size (MB): 2953.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = DopeNetwork()\n",
    "summary(model, (3, 640, 640), device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
